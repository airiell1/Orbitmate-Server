// controllers/aiInfoController.js
const {
  createController
} = require("../utils/serviceFactory");
const config = require("../config");

// =========================
// ğŸ¤– AI ëª¨ë¸ ì •ë³´ (AI Information)
// =========================

/**
 * AI ëª¨ë¸ ì •ë³´ ì„œë¹„ìŠ¤ í•¨ìˆ˜ (ë™ê¸°ì‹)
 */
function getModelsInfoService() {
  const { defaultProvider, gemini, ollama, vertexAi } = config.ai;

  // ëª¨ë¸ ì •ë³´ êµ¬ì„±
  const models = [
    {
      provider: "geminiapi",
      id: gemini.defaultModel,
      name: `Google AI Studio (${gemini.defaultModel})`,
      max_input_tokens: gemini.maxInputTokens || 1048576,
      max_output_tokens: gemini.maxOutputTokens || 8192,
      is_default: defaultProvider === "geminiapi",
      description: "Googleì˜ AI Studioë¥¼ í†µí•´ ì œê³µë˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ê· í˜• ì¡íŒ ì„±ëŠ¥ê³¼ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.",
      strengths: ["ì¼ë°˜ ëŒ€í™”", "ì°½ì˜ì  ê¸€ì“°ê¸°", "ìš”ì•½"],
      availability: gemini.apiKey ? "available" : "unavailable (API Key missing)",
    },
    {
      provider: "ollama",
      id: ollama.defaultModel,
      name: `Ollama (${ollama.defaultModel})`,
      max_input_tokens: ollama.maxInputTokens || 128000,
      max_output_tokens: ollama.maxOutputTokens || 8192,
      is_default: defaultProvider === "ollama",
      description: "ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì…ë‹ˆë‹¤. ë°ì´í„° ë³´ì•ˆ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì— ìœ ë¦¬í•©ë‹ˆë‹¤.",
      strengths: ["ì˜¤í”„ë¼ì¸ ì‚¬ìš©", "ë¹ ë¥¸ ì‘ë‹µ(ë¡œì»¬ í™˜ê²½ ìµœì í™” ì‹œ)", "íŠ¹ì • ì‘ì—… íŒŒì¸-íŠœë‹ ê°€ëŠ¥"],
      availability: ollama.apiUrl ? "available" : "unavailable (API URL missing)",
    },
    {
      provider: "vertexai",
      id: vertexAi.defaultModel,
      name: `Vertex AI (${vertexAi.defaultModel})`,
      max_input_tokens: vertexAi.maxInputTokens || 1048576,
      max_output_tokens: vertexAi.maxOutputTokens || 65535,
      is_default: defaultProvider === "vertexai",
      description: "Google Cloud Vertex AIë¥¼ í†µí•´ ì œê³µë˜ëŠ” ê°•ë ¥í•œ ëª¨ë¸ì…ë‹ˆë‹¤. ì—”í„°í”„ë¼ì´ì¦ˆ ìˆ˜ì¤€ì˜ í™•ì¥ì„±ê³¼ ì•ˆì •ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.",
      strengths: ["ê³ ì„±ëŠ¥", "ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬", "Google Cloud ìƒíƒœê³„ ì—°ë™"],
      availability: vertexAi.projectId && vertexAi.applicationCredentials ? "available" : "unavailable (Credentials missing)",
    },
  ];

  return models;
}

/**
 * AI ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì»¨íŠ¸ë¡¤ëŸ¬ - ServiceFactory íŒ¨í„´ ì ìš©
 */
const getModelsInfoController = createController(
  async () => getModelsInfoService(), // ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ë˜í•‘
  {
    dataExtractor: () => [], // íŒŒë¼ë¯¸í„° ì—†ìŒ
    validations: [], // ìœ íš¨ì„± ê²€ì‚¬ ì—†ìŒ
    errorHandler: (err) => {
      err.code = err.code || "SERVER_ERROR";
      err.message = err.message || "AI ëª¨ë¸ ì •ë³´ ì¡°íšŒ ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
      return err;
    }
  }
);

module.exports = {
  getModelsInfoController,
};