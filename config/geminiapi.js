// config/geminiapi.js - Google Gemini API (AI Studio) ì—°ë™
const { GoogleGenerativeAI } = require("@google/generative-ai");
const config = require("./index"); // ì¤‘ì•™ ì„¤ì • íŒŒì¼ import
const {
  getGeminiTools,
  executeAiTool,
  enhancePromptWithTools,
} = require("../utils/aiTools");
const {
  generateSystemPrompt,
  validateAndCleanPrompt,
  enhancePromptWithContext,
  enhanceUserMessageWithMode,
} = require("../utils/systemPrompt");

const GEMINI_API_KEY = config.ai.gemini.apiKey;

if (!GEMINI_API_KEY && config.ai.defaultProvider === 'geminiapi') {
  // ê¸°ë³¸ ì œê³µìê°€ geminiapiì¼ ë•Œë§Œ ì—ëŸ¬ ì¶œë ¥, ì•„ë‹ˆë©´ ê²½ê³ 
  const message = "GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Gemini APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
  if (config.ai.defaultProvider === 'geminiapi') {
    console.error(message);
  } else {
    console.warn(message);
  }
}

// Google Generative AI ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
const genAI = GEMINI_API_KEY ? new GoogleGenerativeAI(GEMINI_API_KEY) : null;

// ê¸°ë³¸ ëª¨ë¸ ë° ì„¤ì • (ì¤‘ì•™ ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì˜´)
const defaultModel = config.ai.gemini.defaultModel;
const defaultConfig = {
  temperature: config.ai.gemini.temperature || 0.7,
  topP: config.ai.gemini.topP || 0.95,
  topK: config.ai.gemini.topK || 40,
  maxOutputTokens: config.ai.gemini.maxOutputTokens || 8192,
};

// ì•ˆì „ì„± ì„¤ì • (ì™„í™”ëœ ê²€ì—´ ì„¤ì •)
const safetySettings = [
  {
    category: "HARM_CATEGORY_HARASSMENT",
    threshold: "BLOCK_ONLY_HIGH",
  },
  {
    category: "HARM_CATEGORY_HATE_SPEECH",
    threshold: "BLOCK_ONLY_HIGH",
  },
  {
    category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
    threshold: "BLOCK_ONLY_HIGH",
  },
  {
    category: "HARM_CATEGORY_DANGEROUS_CONTENT",
    threshold: "BLOCK_ONLY_HIGH",
  },
];

/**
 * Gemini APIë¡œ ì±„íŒ… ì™„ì„± ìš”ì²­
 * @param {string} currentUserMessage - í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
 * @param {Array} history - ëŒ€í™” ê¸°ë¡ ë°°ì—´
 * @param {string} systemMessageText - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (utils/systemPrompt.jsë¡œ ì²˜ë¦¬ë¨)
 * @param {string} specialModeType - íŠ¹ìˆ˜ ëª¨ë“œ ('stream', 'canvas', 'search' ë“±)
 * @param {Function} streamResponseCallback - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì½œë°±
 * @param {Object} options - ì¶”ê°€ ì˜µì…˜ ê°ì²´
 * @param {Object} context - ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ (IP ì£¼ì†Œ ë“±)
 * @returns {Promise<Object>} AI ì‘ë‹µ ê°ì²´
 */
async function getGeminiApiResponse(
  currentUserMessage,
  history,
  systemMessageText,
  specialModeType,
  streamResponseCallback,
  options = {},
  context = {}
) {
  if (!genAI) {
    // ì´ ì‹œì ì—ì„œ genAIê°€ nullì´ë©´ API í‚¤ê°€ ì—†ê±°ë‚˜ ì´ˆê¸°í™” ì‹¤íŒ¨
    throw new Error("Gemini API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.");
  }

  try {
    // ëª¨ë¸ ì„¤ì •
    const modelName = options.model_id_override || defaultModel;

    // Function Calling ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
    const useTools = options.enableTools !== false; // ê¸°ë³¸ì ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš© í™œì„±í™”
    const tools = useTools ? getGeminiTools() : [];

    const modelConfig = {
      model: modelName,
      generationConfig: {
        temperature: options.temperature || defaultConfig.temperature,
        topP: options.topP || defaultConfig.topP,
        topK: options.topK || defaultConfig.topK,
        maxOutputTokens:
          options.max_output_tokens_override || defaultConfig.maxOutputTokens,
      },
      safetySettings,
    };

    if (tools.length > 0) {
      modelConfig.tools = tools;
    }

    const model = genAI.getGenerativeModel(modelConfig);
    const chatHistory = [];

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ê°œì„ 
    if (systemMessageText) {
      // systemMessageTextê°€ ë¬¸ìì—´ì¸ì§€ í™•ì¸í•˜ê³  ë³€í™˜
      const systemText = typeof systemMessageText === 'string' ? systemMessageText : 
                        (systemMessageText && systemMessageText.content ? systemMessageText.content : String(systemMessageText));
      
      if (systemText && systemText.trim()) {
        // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê²€ì¦ ë° ì •ë¦¬
        const cleanedSystemPrompt = validateAndCleanPrompt(systemText.trim());
      
      // íŠ¹ìˆ˜ ëª¨ë“œì— ë”°ë¥¸ ì»¨í…ìŠ¤íŠ¸ í™•ì¥
      let contextType = null;
      if (specialModeType === "canvas") {
        contextType = "canvas";
      } else if (specialModeType === "search") {
        contextType = "analysis";
      } else if (specialModeType === "chatbot") {
        contextType = "support";
      }
      
      // ì»¨í…ìŠ¤íŠ¸ í™•ì¥ ì ìš©
      const contextEnhancedPrompt = enhancePromptWithContext(cleanedSystemPrompt, contextType);
      
      // ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥ ì‹œ ë„êµ¬ ê´€ë ¨ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
      const finalSystemPrompt = useTools
        ? enhancePromptWithTools(contextEnhancedPrompt)
        : contextEnhancedPrompt;

      chatHistory.push({
        role: "user",
        parts: [{ text: `ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­: ${finalSystemPrompt}` }],
      });
      chatHistory.push({
        role: "model",
        parts: [{ text: "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤." }],
      });
      }
    } else if (useTools) {
      // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ì—†ì„ ë•Œ ë„êµ¬ë§Œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
      const toolsOnlyPrompt = enhancePromptWithTools("");
      chatHistory.push({
        role: "user",
        parts: [{ text: `ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­: ${toolsOnlyPrompt}` }],
      });
      chatHistory.push({
        role: "model",
        parts: [{ text: "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. í•„ìš”ì‹œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤." }],
      });
    }

    // ëŒ€í™” ì´ë ¥ ì²˜ë¦¬ (ì¤‘ë³µ ë°©ì§€ ë¡œì§ ì¶”ê°€)
    if (history && Array.isArray(history)) {
      history.forEach((msg) => {
        const messageText = (msg.parts && msg.parts[0] && msg.parts[0].text) || msg.content;
        if (messageText && messageText.trim() && !chatHistory.some(h => h.parts[0].text === messageText.trim())) {
          if (msg.role === "user") {
            chatHistory.push({ role: "user", parts: [{ text: messageText.trim() }] });
          } else if (msg.role === "assistant" || msg.role === "model") {
            chatHistory.push({ role: "model", parts: [{ text: messageText.trim() }] });
          }
        }
      });
    }

    // ë©”ì‹œì§€ ì „ì²˜ë¦¬ ë° íŠ¹ìˆ˜ ëª¨ë“œ ì²˜ë¦¬ (utils/systemPrompt.jsë¡œ ì´ë™)
    const enhancedMessage = enhanceUserMessageWithMode(currentUserMessage, specialModeType);

    // ë©”ì‹œì§€ ê²€ì¦
    if (!enhancedMessage || enhancedMessage.trim() === "") {
      throw new Error("ë©”ì‹œì§€ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.");
    }

    // ğŸ”§ ì¤‘ë³µ ë°©ì§€: ëŒ€í™” ì´ë ¥ì˜ ë§ˆì§€ë§‰ ë©”ì‹œì§€ê°€ í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ì™€ ê°™ìœ¼ë©´ ì œê±°
    if (chatHistory.length > 0) {
      const lastMessage = chatHistory[chatHistory.length - 1];
      if (lastMessage.role === "user" && 
          lastMessage.parts && 
          lastMessage.parts[0] && 
          lastMessage.parts[0].text === enhancedMessage.trim()) {
        console.log(`[GeminiAPI] ì¤‘ë³µëœ ì‚¬ìš©ì ë©”ì‹œì§€ ë°œê²¬, ì´ë ¥ì—ì„œ ì œê±°: "${enhancedMessage.substring(0, 50)}..."`);
        chatHistory.pop(); // ë§ˆì§€ë§‰ ì¤‘ë³µ ë©”ì‹œì§€ ì œê±°
      }
    }

    const chat = model.startChat({
      history: chatHistory.length > 0 ? chatHistory : [],
    });

    if (streamResponseCallback && typeof streamResponseCallback === "function") {
      console.log(`[GeminiAPI] ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ìš”ì²­ ì²˜ë¦¬ ì¤‘...`);
      try {
        const result = await chat.sendMessageStream(enhancedMessage);
        let fullText = "";
        let hasFunctionCalls = false;
        let finalResult = null;

        for await (const chunk of result.stream) {
          const chunkText = chunk.text();
          if (chunkText) {
            fullText += chunkText;
            streamResponseCallback(chunkText);
          }
          if (chunk.candidates && chunk.candidates.length > 0) {
            const candidate = chunk.candidates[0];
            if (candidate.content && candidate.content.parts) {
              const functionCallParts = candidate.content.parts.filter(part => part.functionCall);
              if (functionCallParts.length > 0) {
                hasFunctionCalls = true;
                break;
              }
            }
          }
        }
        finalResult = await result.response;

        if (hasFunctionCalls || (finalResult.candidates && finalResult.candidates.length > 0)) {
          const candidate = finalResult.candidates[0];
          if (candidate.content && candidate.content.parts) {
            const functionCallParts = candidate.content.parts.filter(part => part.functionCall);
            if (functionCallParts.length > 0) {
              const functionResponses = [];
              for (const part of functionCallParts) {
                const functionCall = part.functionCall;
                const { name, args } = functionCall;
                try {
                  const toolResult = await executeAiTool(name, args, context);
                  functionResponses.push({ functionResponse: { name, response: toolResult } });
                } catch (toolError) {
                  functionResponses.push({ functionResponse: { name, response: { success: false, error: toolError.message } } });
                }
              }
              const followUpResult = await chat.sendMessageStream(functionResponses);
              let followUpText = "";
              for await (const chunk of followUpResult.stream) {
                const chunkText = chunk.text();
                if (chunkText) {
                  followUpText += chunkText;
                  streamResponseCallback(chunkText);
                }
              }
              const followUpFinal = await followUpResult.response;
              const usageMetadata = followUpFinal.usageMetadata || {};
              return {
                content: followUpText,
                actual_input_tokens: usageMetadata.promptTokenCount || 0,
                actual_output_tokens: usageMetadata.candidatesTokenCount || 0,
                total_tokens: usageMetadata.totalTokenCount || 0,
                model_used: modelName,
                provider: "geminiapi",
                finish_reason: "stop",
                streaming: true,
                function_calls_used: functionCallParts.map(part => part.functionCall.name),
              };
            }
          }
        }
        const usageMetadata = finalResult.usageMetadata || {};
        return {
          content: fullText,
          actual_input_tokens: usageMetadata.promptTokenCount || 0,
          actual_output_tokens: usageMetadata.candidatesTokenCount || 0,
          total_tokens: usageMetadata.totalTokenCount || 0,
          model_used: modelName,
          provider: "geminiapi",
          finish_reason: "stop",
          streaming: true,
        };
      } catch (streamError) {
        console.error("Gemini API ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜:", streamError);
        throw streamError;
      }
    } else {
      const result = await chat.sendMessage(enhancedMessage);
      const response = await result.response;
      const candidates = response.candidates;

      if (candidates && candidates.length > 0) {
        const candidate = candidates[0];
        const content = candidate.content;
        if (content && content.parts) {
          const functionCallParts = content.parts.filter(part => part.functionCall);
          if (functionCallParts.length > 0) {
            const functionResponses = [];
            for (const part of functionCallParts) {
              const functionCall = part.functionCall;
              const { name, args } = functionCall;
              try {
                const toolResult = await executeAiTool(name, args, context);
                functionResponses.push({ functionResponse: { name, response: toolResult } });
              } catch (toolError) {
                 functionResponses.push({ functionResponse: { name, response: { success: false, error: toolError.message } } });
              }
            }
            const followUpResult = await chat.sendMessage(functionResponses);
            const followUpResponse = await followUpResult.response;
            const finalContent = followUpResponse.text();
            const usageMetadata = followUpResponse.usageMetadata || {};
            return {
              content: finalContent,
              actual_input_tokens: usageMetadata.promptTokenCount || 0,
              actual_output_tokens: usageMetadata.candidatesTokenCount || 0,
              total_tokens: usageMetadata.totalTokenCount || 0,
              model_used: modelName,
              provider: "geminiapi",
              finish_reason: "stop",
              streaming: false,
              function_calls_used: functionCallParts.map(part => part.functionCall.name),
            };
          }
        }
      }

      const responseContent = response.text();
      const usageMetadata = response.usageMetadata || {};
      return {
        content: responseContent,
        actual_input_tokens: usageMetadata.promptTokenCount || 0,
        actual_output_tokens: usageMetadata.candidatesTokenCount || 0,
        total_tokens: usageMetadata.totalTokenCount || 0,
        model_used: modelName,
        provider: "geminiapi",
        finish_reason: "stop",
      };
    }
  } catch (error) {
    console.error("Gemini API ì˜¤ë¥˜:", error);
    if (error.message?.includes("API_KEY")) {
      throw new Error("Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    } else if (error.message?.includes("QUOTA")) {
      throw new Error("Gemini API í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.");
    } else if (error.message?.includes("SAFETY")) {
      throw new Error("ì•ˆì „ì„± í•„í„°ì— ì˜í•´ ì‘ë‹µì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.");
    } else {
      throw new Error(`Gemini API ìš”ì²­ ì‹¤íŒ¨: ${error.message}`);
    }
  }
}

module.exports = {
  getGeminiApiResponse,
  // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ëŠ” utils/systemPrompt.jsì—ì„œ ë‹´ë‹¹
  // ë„êµ¬ ê´€ë¦¬ëŠ” utils/aiTools.jsì—ì„œ ë‹´ë‹¹
  // genAI ì¸ìŠ¤í„´ìŠ¤ëŠ” ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©
};
